---
title: "CUNY 2020 Analysis"
output: html_notebook
---

# Packages and utilities

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
library(plotrix)
library(stringr)
library(readxl)
library(RColorBrewer)
library(viridis)
library(Hmisc)
library(mvtnorm)
```

```{r}
# Compute the log-likelihood of a new dataset using a fit lme4 model.
logLik_test <- function(lm, test_X, test_y) {
  predictions <- predict(lm, test_X, re.form=NA)
  # Get std.dev. of residual, estimated from train data
  stdev <- sigma(lm)
  # For each prediction--observation, get the density p(obs | N(predicted, model_sigma)) and reduce
  density <- sum(dnorm(test_y, predictions, stdev, log=TRUE))
  return(density)
}

# Compute MSE of a new dataset using a fit lme4 model.
mse_test <- function(lm, test_X, test_y) {
  return(mean((predict(lm, test_X, re.form=NA) - test_y) ^ 2))
}

# Sanity checks
#mylm <- lm(psychometric ~ len + freq + sent_pos, data=train_data)
#c(logLik(mylm), logLik_test(mylm, train_data, train_data$psychometric))
#logLik_test(mylm, test_data, test_data$psychometric)
```

# Data loading and preprocessing

```{r}
lm_data = read.csv("coded_results_spr.csv") %>%
  select(-X)
```

```{r}
brown = lm_data %>%
  filter(corpus == "bnc-brown")

brown_spr = read.csv("./corpora/brown_spr.csv") %>%
  group_by(code) %>%
    # Compute mean RT per token, pooling together subjects
    summarise(rt=mean(time)) %>%
  ungroup()

brown = merge(brown, brown_spr, by="code") %>%
  filter(surprisal > 0) %>%
  mutate(seed = as.factor(seed))
```

```{r}

natural = lm_data %>%
  filter(corpus == "natural-stories")

natural_spr = read.csv("./corpora/natural_stories_rts.csv", sep="\t")%>%
  mutate(code = paste(zone, item, sep = "_")) %>%
  group_by(code, word) %>%
    # Compute mean RT per token, pooling together subjects
    summarise(rt=mean(RT)) %>%
  ungroup() %>%
  select(-word)

natural = merge(natural, natural_spr, by="code") %>%
  filter(surprisal > 0) %>%
  mutate(seed = as.factor(seed))

```


```{r}
all_data = rbind(brown, natural) %>%
  select(-code) %>%
  rename("psychometric" = rt)

dundee = read.csv("coded_results_dundee.csv") %>%
  rename("sent_pos" = position,
         "psychometric" = gaze) %>%
  mutate(corpus = "dundee") %>%
  select(-X, -text) %>%
  mutate(seed = as.factor(seed))

all_data = rbind(all_data, dundee) %>%
  drop_na()

```

# Linear model training and evaluation

```{r}

# Randomly subsample data to produce train/test splits.
train_size <- floor(0.8 * nrow(all_data))
train_indices = sample(seq_len(nrow(all_data)), size=train_size)
train_data <- all_data[train_indices, ]
test_data <- all_data[-train_indices, ]

# Compute linear model stats for the given training data subset and full test data.
# Automatically subsets the test data to match the relevant group for which we are training a linear model.
get_lm_data <- function(df, test_data, formula) {
  this_lm <- lm(formula, data=df);
  this_test_data <- semi_join(test_data, df, by=c("training", "model", "seed", "corpus"));
  summarise(df,
            log_lik = logLik(this_lm, REML = F),
            test_lik = logLik_test(this_lm, this_test_data, this_test_data$psychometric),
            test_mse = mse_test(this_lm, this_test_data, this_test_data$psychometric))
}

# Compute a baseline linear model for each model--training--seed--RT-corpus combination.
baselines = train_data %>%
  group_by(model, training, seed, corpus) %>%
    do(get_lm_data(., test_data, psychometric ~ len + freq + sent_pos)) %>%
  ungroup() %>%
  mutate(seed = as.factor(seed))

# Compute a full linear model for each model--training--seed-RT-corpus combination
full_models = train_data %>%
  group_by(model, training, seed, corpus) %>%
    do(get_lm_data(., test_data, psychometric ~ surprisal + len + freq + sent_pos)) %>%
  ungroup() %>%
  mutate(seed = as.factor(seed))
```

```{r}

metric <- "ΔLogLik"
# metric <- "-ΔMSE"

d_lik = full_models %>%
  right_join(baselines, suffix=c(".full", ".baseline"),
             by=c("seed", "training", "model", "corpus")) %>%
  mutate(delta_test_metric = test_lik.full - test_lik.baseline) %>%
  # mutate(delta_test_metric = -(test_mse.full - test_mse.baseline)) %>%
  # Remove the raw metrics and keep just the delta.
  select(-log_lik.full, -test_lik.full, -test_mse.full,
         -log_lik.baseline, -test_lik.baseline, -test_mse.baseline
         ) %>%
  spread(corpus, delta_test_metric) %>%
  drop_na()

d_lik
```

```{r}
# Sanity check: training on train+test data should yield improved performance over training on just training data. (When evaluating on test data.)

# full_baselines = all_data %>%
#   group_by(model, training, seed, corpus) %>%
#   summarise(baseline_train_all_test_lik = logLik_test(lm(psychometric ~ len + freq + sent_pos, data=.), semi_join(test_data, ., by=c("training", "model", "seed", "corpus")), semi_join(test_data, ., by=c("training", "model", "seed", "corpus"))$psychometric)) %>%
#   ungroup()
# full_baselines
# 
# full_baselines %>%
#   right_join(baselines, by=c("seed", "training", "model", "corpus")) %>%
#   mutate(delta=baseline_train_all_test_lik-baseline_test_lik) %>%
#   select(-baseline_lik) # %>%
#   #select(-baseline_test_lik, -baseline_train_all_test_lik, -baseline_lik, -baseline_test_mse)
```

# Load model data (SyntaxGym, PPL)

```{r}
  
d_all = read.csv("all_results_with_ppl_sg.csv") %>%
  mutate(train_size = case_when(training == "bllip-lg" ~ 42,
                                training == "bllip-md" ~ 15,
                                training == "bllip-sm" ~ 5,
                                training == "bllip-xs" ~ 1)) %>%
  mutate(seed = as.factor(seed)) %>%
  select(-X, -corpus, -model_key, -mse, -corr, -l1, -train_l1) %>%
  distinct(model, training, seed, .keep_all = TRUE)

d_comb = d_all %>%
  right_join(d_lik, by=c("seed", "training", "model")) %>%
  drop_na() %>%
  gather(corpus, delta_test_metric, 7:9)


```

# Visualizations

```{r}

d_comb %>%
  ggplot(aes(x=sg_score, y=delta_test_metric, color=training)) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab(metric) +
    xlab("Syntax Generalization Score") +
    ggtitle("Syntactic Generalization vs. Predictive Power") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/sg_loglik.png",height=5,width=6)

```

```{r}

d_comb %>%
  #filter(model != "5gram") %>%
  #filter(corpus == "dundee") %>%
  ggplot(aes(x=sg_score, y=delta_test_metric, color=model)) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab(metric) +
    xlab("Syntax Generalization Score") +
    ggtitle("Syntactic Generalization vs. Predictive Power") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/sg_loglik.png",height=5,width=6)
```

```{r}
d_corp = d_comb %>%
  filter(model != "5gram") %>%
  group_by(corpus) %>%
    # Compute residuals from an RT ~ PPL regression for each model--training--seed
    mutate(resid.ppl = resid(lm(delta_test_metric ~ training:test_ppl))) %>%
  ungroup()

# Now plot residual vs SG
d_corp %>%
  ggplot(aes(x=sg_score, y=resid.ppl,
             color=model
             )) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab(paste("Residual", metric)) +
    xlab("Syntax Generalization Score") +
    ggtitle("Syntactic Generalization vs. Predictive Power") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
```


```{r}
d_corp = d_comb %>%
  filter(corpus == "dundee") %>%
  filter(model != "5gram")
lm1 = lm(delta_test_metric ~ training:test_ppl, data = d_corp)
lm2 = lm(delta_test_metric ~ training:test_ppl + sg_score, data = d_corp)
anova(lm1, lm2)
summary(lm2)


```


```{r}
d_comb %>%
  filter(model != "5gram") %>%
  filter(model != "ordered-neurons") %>%
  #filter(corpus == "dundee") %>%
  ggplot(aes(x=test_ppl, y=delta_test_metric, color=training)) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=2.5) +
    ylab(metric) +
    xlab("Test Perplexity") +
    ggtitle("Test Perplexity vs. Predictive Power") +
    scale_color_manual(values = c("#440154FF", "#39568CFF", "#1F968BFF", "#73D055FF")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=12),
          strip.text.x = element_text(size=12),
          legend.text=element_text(size=12),
          axis.title=element_text(size=12),
          legend.position = "bottom")
#ggsave("./cogsci_images/ppl_loglik.png",height=5,width=6)

```

```{r}
d_comb %>%
  mutate(train_size = log(train_size)) %>%
  ggplot(aes(x=train_size, y=delta_test_metric, color=model)) +
    geom_smooth(method="lm", se=T, alpha=0.5) +
    geom_point(stat="identity", position="dodge", alpha=0.5, size=3) +
    ylab(metric) +
    xlab("Log Million Training Tokens") +
    ggtitle("Training Size vs. Predictive Power") +
    facet_grid(corpus~model, scales="free") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/training_loglik.png",height=5,width=6)

```


```{r}
d_comb %>%
  mutate(train_size = log(train_size)) %>%
  ggplot(aes(x=train_size, y=sg_score, color=model)) +
    geom_smooth(method="lm", se=T, alpha=0.5) +
    geom_point(stat="identity", position="dodge", alpha=0.5, size=3) +
    ylab("SG SCore") +
    xlab("Log Million Training Tokens") +
    ggtitle("Training Size vs. Syntactic Generalization") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(~model, scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/training_sg.png",height=5,width=6)

```

```{r}
# Correlation Testing

#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "natural-stories", model == "rnng"))
#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "natural-stories", model == "vanilla"))

#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "dundee", model == "rnng"))
#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "dundee", model == "vanilla"))

#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "bnc-brown", model == "rnng"))
#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "bnc-brown", model == "vanilla"))

#cor.test(formula = ~ train_size + sg_score, data = d_comb %>% filter(corpus == "bnc-brown", model == "rnng"))
#cor.test(formula = ~ train_size + sg_score, data = d_comb %>% filter(corpus == "bnc-brown", model == "vanilla"))

#mean(c(0.9118399, 0.7408788, 0.8731879, 0.9482418, 0.8596604, 0.649311 ))
#mean(c(0.5496241, 0.5285862 ))


```

```{r}
all_data %>%
  filter(model != "ordered-neurons") %>%
  filter(surprisal < 15, surprisal > 0) %>%
  mutate(surp_fac = cut(surprisal, 15, labels = F)) %>%
  group_by(model, corpus, training, surp_fac) %>%
    summarise(m=mean(psychometric),
              s=std.error(psychometric),
              upper=m+1.96*s,
              lower=m-1.96*s) %>%
    ungroup() %>%
  ggplot(aes(x=surp_fac, y=m, ymin=lower, ymax=upper, color=training)) +
    stat_smooth(method="lm", se=T, alpha=0.5) +
    geom_errorbar(color="black", width=.2, position=position_dodge(width=.9), alpha=0.3) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab("Psychometric (ms)") +
    xlab("Surprisal (bits)") +
    ggtitle("Surprisal vs. Reading Time / Gaze Duration") +
    facet_grid(corpus~model, scales = "free") +
    scale_color_manual(values = c("#440154FF", "#39568CFF", "#1F968BFF", "#73D055FF")) +
    theme(axis.text=element_text(size=14),
          axis.text.x = element_text(angle = 90, hjust = 1),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/surp_corr.png",height=5,width=12)

```








