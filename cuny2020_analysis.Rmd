---
title: "CUNY 2020 Analysis"
output: html_notebook
---

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
library(plotrix)
library(stringr)
library(readxl)
library(RColorBrewer)
library(viridis)
library(Hmisc)
library(mvtnorm)
```

```{r}
# Compute the log-likelihood of a new dataset using a fit lme4 model.
logLik_test <- function(lm, test_X, test_y) {
  predictions <- predict(lm, test_X, re.form=NA)
  # Get std.dev. of residual, estimated from train data
  stdev <- sigma(lm)
  # For each prediction--observation, get the density p(obs | N(predicted, model_sigma)) and reduce
  density <- sum(dnorm(test_y, predictions, stdev, log=TRUE))
  return(density)
}

mse_test <- function(lm, test_X, test_y) {
  return(mean((predict(lm, test_X, re.form=NA) - test_y) ^ 2))
}

#mylm <- lm(psychometric ~ len + freq + sent_pos, data=train_data)
#c(logLik(mylm), logLik_test(mylm, train_data, train_data$psychometric))
#logLik_test(mylm, test_data, test_data$psychometric)
```

```{r}
lm_data = read.csv("coded_results_spr.csv") %>%
  select(-X)
```

```{r}
brown = lm_data %>%
  filter(corpus == "bnc-brown")

brown_spr = read.csv("./corpora/brown_spr.csv") %>%
  group_by(code) %>%
    summarise(rt=mean(time)) %>%
  ungroup()

brown = merge(brown, brown_spr, by="code") %>%
  filter(surprisal > 0) %>%
  mutate(seed = as.factor(seed))
```

```{r}

natural = lm_data %>%
  filter(corpus == "natural-stories")

natural_spr = read.csv("./corpora/natural_stories_rts.csv", sep="\t")%>%
  mutate(code = paste(zone, item, sep = "_")) %>%
  group_by(code, word) %>%
    summarise(rt=mean(RT)) %>%
  ungroup() %>%
  select(-word)

natural = merge(natural, natural_spr, by="code") %>%
  filter(surprisal > 0) %>%
  mutate(seed = as.factor(seed))

```


```{r}
all_data = rbind(brown, natural) %>%
  select(-code) %>%
  rename("psychometric" = rt)

dundee = read.csv("coded_results_dundee.csv") %>%
  rename("sent_pos" = position,
         "psychometric" = gaze) %>%
  mutate(corpus = "dundee") %>%
  select(-X, -text) %>%
  mutate(seed = as.factor(seed))

all_data = rbind(all_data, dundee) %>%
  drop_na()

```



```{r}

train_size <- floor(0.8 * nrow(all_data))
train_indices = sample(seq_len(nrow(all_data)), size=train_size)
train_data <- all_data[train_indices, ]
test_data <- all_data[-train_indices, ]

baselines = train_data %>%
  group_by(training, model, seed, corpus) %>%
      summarise(baseline_lik = logLik(lm(psychometric ~ len + freq + sent_pos), REML = F),
                baseline_test_lik = logLik_test(lm(psychometric ~ len + freq + sent_pos), test_data, test_data$psychometric),
                baseline_test_mse = mse_test(lm(psychometric ~ len + freq + sent_pos), test_data, test_data$psychometric)) %>%
  ungroup()
baselines

d_lik_pre = train_data %>%
  group_by(model, training, seed, corpus) %>%
    summarise(log_lik = logLik(lm(psychometric ~ surprisal + len + freq + sent_pos), REML = F),
              test_lik = logLik_test(lm(psychometric ~ surprisal + len + freq + sent_pos), test_data, test_data$psychometric),
              test_mse = mse_test(lm(psychometric ~ surprisal + len + freq + sent_pos), test_data, test_data$psychometric)) %>%
  ungroup() %>%
  mutate(seed = as.factor(seed))

# metric <- "ΔLogLik"
metric <- "-ΔMSE"

d_lik = d_lik_pre %>%
  right_join(baselines, by=c("seed", "training", "model", "corpus")) %>%
  # mutate(delta_test_metric = test_lik - baseline_test_lik) %>%
  mutate(delta_test_metric = -(test_mse - baseline_test_mse)) %>%
  select(-log_lik, -test_lik, -baseline_lik, -baseline_test_lik, -test_mse, -baseline_test_mse) %>%
  spread(corpus, delta_test_metric) %>%
  drop_na()

d_lik

```


```{r}
  
d_all = read.csv("all_results_with_ppl_sg.csv") %>%
  mutate(train_size = case_when(training == "bllip-lg" ~ 42,
                                training == "bllip-md" ~ 15,
                                training == "bllip-sm" ~ 5,
                                training == "bllip-xs" ~ 1)) %>%
  mutate(seed = as.factor(seed)) %>%
  select(-X, -corpus, -model_key, -mse, -corr, -l1, -train_l1)

d_all
  

d_comb = d_all %>%
  right_join(d_lik, by=c("seed", "training", "model")) %>%
  drop_na() %>%
  gather(corpus, delta_test_metric, 7:9)

d_comb


```


```{r}

d_comb %>%
  ggplot(aes(x=sg_score, y=delta_test_metric, color=training)) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab(metric) +
    xlab("Syntax Generalization Score") +
    ggtitle("Syntactic Generalization vs. Predictive Power") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/sg_loglik.png",height=5,width=6)

```

```{r}

d_comb %>%
  #filter(model != "5gram") %>%
  #filter(corpus == "dundee") %>%
  ggplot(aes(x=sg_score, y=delta_test_metric, color=model)) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab(metric) +
    xlab("Syntax Generalization Score") +
    ggtitle("Syntactic Generalization vs. Predictive Power") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/sg_loglik.png",height=5,width=6)
```


```{r}
d_corp = d_comb %>%
  filter(corpus == "dundee") %>%
  filter(model != "5gram")
lm1 = lm(delta_test_metric ~ training:test_ppl, data = d_corp)
lm2 = lm(delta_test_metric ~ training:test_ppl + sg_score, data = d_corp)
anova(lm1, lm2)
summary(lm2)


```


```{r}
d_comb %>%
  filter(model != "5gram") %>%
  filter(model != "ordered-neurons") %>%
  #filter(corpus == "dundee") %>%
  ggplot(aes(x=test_ppl, y=delta_test_metric, color=training)) +
    geom_smooth(method="lm", se=T) +
    geom_point(stat="identity", position="dodge", alpha=1, size=2.5) +
    ylab(metric) +
    xlab("Test Perplexity") +
    ggtitle("Test Perplexity vs. Predictive Power") +
    scale_color_manual(values = c("#440154FF", "#39568CFF", "#1F968BFF", "#73D055FF")) +
    facet_grid(corpus~., scales="free") +
    theme(axis.text=element_text(size=12),
          strip.text.x = element_text(size=12),
          legend.text=element_text(size=12),
          axis.title=element_text(size=12),
          legend.position = "bottom")
#ggsave("./cogsci_images/ppl_loglik.png",height=5,width=6)

```

```{r}
d_comb %>%
  mutate(train_size = log(train_size)) %>%
  ggplot(aes(x=train_size, y=delta_test_metric, color=model)) +
    geom_smooth(method="lm", se=T, alpha=0.5) +
    geom_point(stat="identity", position="dodge", alpha=0.5, size=3) +
    ylab(metric) +
    xlab("Log Million Training Tokens") +
    ggtitle("Training Size vs. Predictive Power") +
    facet_grid(corpus~model, scales="free") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/training_loglik.png",height=5,width=6)

```


```{r}
d_comb %>%
  mutate(train_size = log(train_size)) %>%
  ggplot(aes(x=train_size, y=sg_score, color=model)) +
    geom_smooth(method="lm", se=T, alpha=0.5) +
    geom_point(stat="identity", position="dodge", alpha=0.5, size=3) +
    ylab("SG SCore") +
    xlab("Log Million Training Tokens") +
    ggtitle("Training Size vs. Syntactic Generalization") +
    #scale_color_manual(values = c("#A42EF1", "#3894C8")) +
    facet_grid(~model, scales="free") +
    theme(axis.text=element_text(size=14),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/training_sg.png",height=5,width=6)

```

```{r}
# Correlation Testing

#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "natural-stories", model == "rnng"))
#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "natural-stories", model == "vanilla"))

#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "dundee", model == "rnng"))
#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "dundee", model == "vanilla"))

#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "bnc-brown", model == "rnng"))
#cor.test(formula = ~ train_size + delta_lik, data = d_comb %>% filter(corpus == "bnc-brown", model == "vanilla"))

#cor.test(formula = ~ train_size + sg_score, data = d_comb %>% filter(corpus == "bnc-brown", model == "rnng"))
#cor.test(formula = ~ train_size + sg_score, data = d_comb %>% filter(corpus == "bnc-brown", model == "vanilla"))

#mean(c(0.9118399, 0.7408788, 0.8731879, 0.9482418, 0.8596604, 0.649311 ))
#mean(c(0.5496241, 0.5285862 ))


```

```{r}
all_data %>%
  filter(model != "ordered-neurons") %>%
  filter(surprisal < 15, surprisal > 0) %>%
  mutate(surp_fac = cut(surprisal, 15, labels = F)) %>%
  group_by(model, corpus, training, surp_fac) %>%
    summarise(m=mean(psychometric),
              s=std.error(psychometric),
              upper=m+1.96*s,
              lower=m-1.96*s) %>%
    ungroup() %>%
  ggplot(aes(x=surp_fac, y=m, ymin=lower, ymax=upper, color=training)) +
    stat_smooth(method="lm", se=T, alpha=0.5) +
    geom_errorbar(color="black", width=.2, position=position_dodge(width=.9), alpha=0.3) +
    geom_point(stat="identity", position="dodge", alpha=1, size=3) +
    ylab("Psychometric (ms)") +
    xlab("Surprisal (bits)") +
    ggtitle("Surprisal vs. Reading Time / Gaze Duration") +
    facet_grid(corpus~model, scales = "free") +
    scale_color_manual(values = c("#440154FF", "#39568CFF", "#1F968BFF", "#73D055FF")) +
    theme(axis.text=element_text(size=14),
          axis.text.x = element_text(angle = 90, hjust = 1),
          strip.text.x = element_text(size=14),
          legend.text=element_text(size=14),
          axis.title=element_text(size=18),
          legend.position = "bottom")
#ggsave("./cogsci_images/surp_corr.png",height=5,width=12)

```








