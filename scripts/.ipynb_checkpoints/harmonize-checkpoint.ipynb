{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Paths\n",
    "FREQUECNY_CORPUS_PATH = \"/Users/wilcoxeg/Documents/resources/data/wikitext-2/wiki.train.tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word frequency statistics for control features\n",
    "word_freq = Counter(open(FREQUECNY_CORPUS_PATH, \"r\").read().split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize lists of <(word, int),(word, int)> pairs\n",
    "# Discards pairs where words do not match\n",
    "\n",
    "def harmonize_rows(ref, d):\n",
    "    result = []\n",
    "    curr_d = d.pop(0)\n",
    "    curr_ref = ref.pop(0)\n",
    "    \n",
    "    while len(d) > 10:\n",
    "        #print(curr_d[2] + \" \" + curr_ref[0])\n",
    "        if curr_d[0] == curr_ref[1]:\n",
    "            #print(\"===\" + curr_d[2] + \"-\" + curr_ref[0])\n",
    "            result.append(curr_d + curr_ref)\n",
    "            curr_d = d.pop(0)\n",
    "            curr_ref = ref.pop(0)\n",
    "        # If current token is unked, then pop both\n",
    "        elif \"UNK\" in curr_d[0]:\n",
    "            curr_d = d.pop(0)\n",
    "            curr_ref = ref.pop(0)\n",
    "        # If current ref has punctuation, pop both\n",
    "        elif not curr_ref[1].isalpha():\n",
    "            curr_ref = ref.pop(0)\n",
    "            curr_d = d.pop(0)\n",
    "        #If the current word is the end of a line\n",
    "        elif \"EOL\" in curr_ref[1]:\n",
    "            curr_ref = ref.pop(0)\n",
    "            curr_d = d.pop(0)\n",
    "        else:\n",
    "            curr_d = d.pop(0)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def merge_model_results():\n",
    "    \n",
    "    final_df = []\n",
    "    \n",
    "    models = [f for f in os.listdir(\"../data/model_results\") if not f.startswith(\".\")]\n",
    "    for m in models:\n",
    "        print(\"Harmonizing results for \" + m)\n",
    "        test_corpus = [f for f in os.listdir(\"../data/model_results/\" + m) if not f.startswith(\".\")]\n",
    "        for tc in test_corpus:\n",
    "            test_files = [f for f in os.listdir(\"../data/model_results/\" + m + \"/\" + tc) if not f.startswith(\".\")]\n",
    "            \n",
    "            for tf in test_files:\n",
    "                if tf == \"UNKS\":\n",
    "                    print(\"TODO: UNKS\")\n",
    "                    continue\n",
    "                \n",
    "                tf = tf.split(\"_\")\n",
    "                test_filename = tf[0]\n",
    "                model_architecture = tf[1]\n",
    "                training_data = tf[2]\n",
    "                seed = tf[3].replace(\".csv\", \"\")\n",
    "                \n",
    "                # Special handling for the Dundee corpus\n",
    "                if tc == \"dundee\":\n",
    "                    gold_test_filename = test_filename.replace(\"wrdp\", \"\") + \"_avg\"\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + gold_test_filename + \".txt\", sep=\"\\t\", names=[\"word\", \"surprisal\"])\n",
    "                    gold_standard.insert(0, 'code', range(0,len(gold_standard)))\n",
    "                    gold_standard[\"code\"] = gold_standard[\"code\"] + int(test_filename.replace(\"tx\", \"\").replace(\"wrdp\", \"\")) * 10000\n",
    "                else:\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + test_filename + \".txt\", sep=\"\\t\")\n",
    "                                    \n",
    "                model_results = \"_\".join([test_filename, model_architecture, training_data, seed])\n",
    "                model_path = \"/\".join([\"../data/model_results\", m, tc, model_results])\n",
    "                model_results = pd.read_csv(model_path+\".csv\", sep=\"\\t\")\n",
    "            \n",
    "                # TODO: EOL Handleing\n",
    "                \n",
    "                model_results = [tuple(x)[2:4] for x in model_results.values.tolist()]\n",
    "                gold_standard = [tuple(x) for x in gold_standard.values.tolist()]\n",
    "                \n",
    "                harmonized_results = harmonize_rows(gold_standard, model_results)\n",
    "                \n",
    "                result = [tuple((x[2], x[0], x[1], x[4], tc, model_architecture, training_data, seed, len(x[0]), math.log(word_freq[x[0]]+1))) for x in harmonized_results]\n",
    "                final_df.extend(result)\n",
    "                \n",
    "    df = pd.DataFrame(final_df)\n",
    "    df.columns = [\"code\", \"word\", \"surprisal\", \"psychometric\", \"corpus\", \"model\", \"training\", \"seed\", \"len\", \"freq\"]\n",
    "    df.head()\n",
    "    df.to_csv(\"../data/harmonized_results.csv\")\n",
    "\n",
    "merge_model_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
