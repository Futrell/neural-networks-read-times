{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word frequency statistics for control features\n",
    "word_freq = Counter()\n",
    "with open(\"../data/wikitext-2_train_vocab.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        token, freq = line.strip().split(\"\\t\")\n",
    "        word_freq[token] = int(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize lists of <(word, int),(word, int)> pairs\n",
    "# Discards pairs where words do not match\n",
    "\n",
    "punct_at_end_re = re.compile(r\"\\W+$\")\n",
    "punct_at_start_re = re.compile(r\"^\\W+\")\n",
    "\n",
    "contractions_re = re.compile(r\"([^' ])('ll|'LL|'re|'RE|'ve|'VE|n't|N'T|not|NOT|'[sS]|'[mM]|'[dD]|')\")\n",
    "\n",
    "mismatches = Counter()\n",
    "biggest_mismatch_code, _ = mismatches_old.most_common(1)[0]\n",
    "\n",
    "def harmonize_rows(ref, d):\n",
    "    result = []\n",
    "    curr_d = d.pop(0)\n",
    "    curr_ref = ref.pop(0)\n",
    "    \n",
    "    to_print = 0\n",
    "    mismatched = [0, None]\n",
    "    while len(d) > 10:\n",
    "        model_token, surprisal = curr_d\n",
    "        code, rt_token, rt = curr_ref\n",
    "        \n",
    "        if punct_at_start_re.search(rt_token):\n",
    "            to_print = 10\n",
    "            \n",
    "        if to_print > 0:\n",
    "            #print(\"\\t\", code, model_token, surprisal, rt_token)\n",
    "            to_print -= 1\n",
    "            if to_print == 0:\n",
    "                pass\n",
    "                #print(\"=======\")\n",
    "                \n",
    "        if code > biggest_mismatch_code - 5 and code < biggest_mismatch_code + 5:\n",
    "            print(\"\\t\", code if code != biggest_mismatch_code else \"**\" + str(code), model_token, surprisal, rt_token)\n",
    "                \n",
    "        if mismatched[0] == 5:\n",
    "            mismatches[mismatched[1]] += 1\n",
    "        \n",
    "        #print(curr_d[2] + \" \" + curr_ref[0])\n",
    "        if model_token == rt_token:\n",
    "            #print(\"===\" + curr_d[2] + \"-\" + curr_ref[0])\n",
    "            result.append(curr_d + curr_ref)\n",
    "            curr_d = d.pop(0)\n",
    "            curr_ref = ref.pop(0)\n",
    "            mismatched = [0, None]\n",
    "        else:\n",
    "            if mismatched[0] == 0:\n",
    "                mismatched = [1, code]\n",
    "            else:\n",
    "                mismatched[0] += 1\n",
    "            # If current token is unked, then pop both\n",
    "            if \"UNK\" in model_token:\n",
    "                curr_d = d.pop(0)\n",
    "                curr_ref = ref.pop(0)\n",
    "            # If current ref has trailing punctuation, remove and re-check\n",
    "            elif punct_at_end_re.search(rt_token):\n",
    "                rt_token_new = punct_at_end_re.sub(\"\", rt_token)\n",
    "                curr_ref = (code, rt_token_new, rt)\n",
    "\n",
    "                # If next model token(s) are that punctuation, drop those tokens\n",
    "                match = punct_at_end_re.findall(rt_token)[0]\n",
    "                while match.startswith(d[0][0]):\n",
    "                    match = match[len(d[0][0]):]\n",
    "                    d.pop(0)\n",
    "            # If current ref has leading punctuation, remove and re-check\n",
    "            elif punct_at_start_re.search(rt_token):\n",
    "                rt_token_new = punct_at_start_re.sub(\"\", rt_token)\n",
    "                curr_ref = (code, rt_token_new, rt)\n",
    "\n",
    "                # If current model token(s) are that punctuation, drop those tokens\n",
    "                match = punct_at_start_re.findall(rt_token)[0]\n",
    "                while match.startswith(model_token):\n",
    "                    match = match[len(model_token):]\n",
    "                    model_token, surprisal = d.pop(0)\n",
    "\n",
    "                curr_d = (model_token, surprisal)\n",
    "            # de-tokenize PTB splits of contractions\n",
    "            elif contractions_re.search(rt_token):\n",
    "                ideal_tokenized_form = tuple(contractions_re.sub(r\"\\1 \\2\", rt_token).split(\" \"))\n",
    "\n",
    "                # Make sure we have the expanded form here in the model tokenization\n",
    "                future_model_tokens = d[:len(ideal_tokenized_form) - 1]\n",
    "                model_token_full = [model_token] + [tok for tok, _ in future_model_tokens]\n",
    "                if ideal_tokenized_form == tuple(model_token_full):\n",
    "                    # Build a little synthetic `curr_d`, `curr_ref` by adding surprisals\n",
    "                    curr_d = (\"\".join(model_token_full), surprisal + sum(surp for _, surp in future_model_tokens))\n",
    "                    d = d[len(future_model_tokens):]\n",
    "                else:\n",
    "                    curr_d = d.pop(0)\n",
    "            # If current ref has leading punctuation, pop both\n",
    "            elif not rt_token.isalpha():\n",
    "                curr_ref = ref.pop(0)\n",
    "                curr_d = d.pop(0)\n",
    "            #If the current word is the end of a line\n",
    "            elif \"EOL\" in rt_token:\n",
    "                curr_ref = ref.pop(0)\n",
    "                curr_d = d.pop(0)\n",
    "            else:\n",
    "                curr_d = d.pop(0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727b9c720ea246528cab75f3efc05d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Harmonizing models', max=4.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonizing results for 5gram\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee103d56dede4f48bd869a2e5c4ca1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=80.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a942e61ab52c4e5fb8cf0965e169249c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=4.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 50502 make 7.891324061672032 make\n",
      "\t 50503 my 11.031233966474128 my\n",
      "\t 50504 hair 9.035856975741627 hair\n",
      "\t 50505 like 11.489323788952227 like\n",
      "\t **50506 Elvis 18.36795988068078 Elvis's?'\n",
      "\t **50506 Elvis 18.36795988068078 Elvis's\n",
      "\t 50507 's 8.84148195957268 I\n",
      "\t 50507 ? 14.337447935463047 I\n",
      "\t 50507 ' 4.130624192383613 I\n",
      "\t 50507 I 10.713245580325928 I\n",
      "\t 50508 asked 8.177121540433163 asked.\n",
      "\t 50508 asked 8.177121540433163 asked\n",
      "\t 50509 The 2.6239870675945296 The\n",
      "\t 50510 barber 24.2958996791218 barber,\n",
      "\t 50510 barber 24.2958996791218 barber\n",
      "\t 50502 make 9.068704210480652 make\n",
      "\t 50503 my 12.934874773941024 my\n",
      "\t 50504 hair 9.483685675121167 hair\n",
      "\t 50505 like 11.226122102907862 like\n",
      "\t **50506 Elvis 20.85481548613818 Elvis's?'\n",
      "\t **50506 Elvis 20.85481548613818 Elvis's\n",
      "\t 50507 's 8.35127796323083 I\n",
      "\t 50507 ? 14.868813485445399 I\n",
      "\t 50507 ' 5.101830475959195 I\n",
      "\t 50507 I 12.910367591482274 I\n",
      "\t 50508 asked 9.389981133860633 asked.\n",
      "\t 50508 asked 9.389981133860633 asked\n",
      "\t 50509 The 2.5940555494832624 The\n",
      "\t 50510 UNK-LC-er 11.334468375969735 barber,\n",
      "\t 50502 make 6.491848046905867 make\n",
      "\t 50503 my 9.85528873906898 my\n",
      "\t 50504 hair 9.30515042340832 hair\n",
      "\t 50505 like 9.41051292343548 like\n",
      "\t **50506 Elvis 12.739534230041082 Elvis's?'\n",
      "\t **50506 Elvis 12.739534230041082 Elvis's\n",
      "\t 50507 's 4.898172670196464 I\n",
      "\t 50507 ? 13.307865845604091 I\n",
      "\t 50507 ' 3.615438033416345 I\n",
      "\t 50507 I 8.12764856175601 I\n",
      "\t 50508 asked 9.350842685787702 asked.\n",
      "\t 50508 asked 9.350842685787702 asked\n",
      "\t 50509 The 2.6143962363012534 The\n",
      "\t 50510 barber 20.689458294610333 barber,\n",
      "\t 50510 barber 20.689458294610333 barber\n",
      "\t 50502 make 7.466986828639305 make\n",
      "\t 50503 my 10.267057462710435 my\n",
      "\t 50504 hair 9.33967694756717 hair\n",
      "\t 50505 like 9.959642838029245 like\n",
      "\t **50506 Elvis 17.39904563228406 Elvis's?'\n",
      "\t **50506 Elvis 17.39904563228406 Elvis's\n",
      "\t 50507 's 7.118553412060847 I\n",
      "\t 50507 ? 12.731089718446643 I\n",
      "\t 50507 ' 3.0317561552519985 I\n",
      "\t 50507 I 6.6673321250079916 I\n",
      "\t 50508 asked 8.827488807587903 asked.\n",
      "\t 50508 asked 8.827488807587903 asked\n",
      "\t 50509 The 2.628543286600972 The\n",
      "\t 50510 barber 20.932898192514354 barber,\n",
      "\t 50510 barber 20.932898192514354 barber\n",
      "\n",
      "Harmonizing results for rnng\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135218a7fc9d4e5c80d2546773a9f0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=180.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5cfd0ba6b9460c904055ad3179da97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=9.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 50502 make 2.53153 make\n",
      "\t 50503 my 5.08552 my\n",
      "\t 50504 hair 7.62017 hair\n",
      "\t 50505 like 5.27123 like\n",
      "\t **50506 Elvis 10.7144 Elvis's?'\n",
      "\t **50506 Elvis 10.7144 Elvis's\n",
      "\t 50507 's 11.8409 I\n",
      "\t 50507 ? 2.91505 I\n",
      "\t 50507 ' 6.04245 I\n",
      "\t 50507 I 7.416860000000001 I\n",
      "\t 50508 asked 6.267119999999999 asked.\n",
      "\t 50508 asked 6.267119999999999 asked\n",
      "\t 50509 The 1.8348099999999998 The\n",
      "\t 50510 UNK-LC-er 7.82015 barber,\n",
      "\t 50502 make 2.88469 make\n",
      "\t 50503 my 4.447690000000001 my\n",
      "\t 50504 hair 8.193760000000001 hair\n",
      "\t 50505 like 6.21475 like\n",
      "\t **50506 Elvis 10.5518 Elvis's?'\n",
      "\t **50506 Elvis 10.5518 Elvis's\n",
      "\t 50507 's 10.0458 I\n",
      "\t 50507 ? 0.23756 I\n",
      "\t 50507 ' 6.964010000000001 I\n",
      "\t 50507 I 5.5833900000000005 I\n",
      "\t 50508 asked 6.827189999999999 asked.\n",
      "\t 50508 asked 6.827189999999999 asked\n",
      "\t 50509 The 1.8960400000000002 The\n",
      "\t 50510 UNK-LC-er 8.2993 barber,\n",
      "\t 50502 make 3.76663 make\n",
      "\t 50503 my 4.3631 my\n",
      "\t 50504 hair 6.84824 hair\n",
      "\t 50505 like 5.4942 like\n",
      "\t **50506 Elvis 8.980789999999999 Elvis's?'\n",
      "\t **50506 Elvis 8.980789999999999 Elvis's\n",
      "\t 50507 's 2.52429 I\n",
      "\t 50507 ? 1.42889 I\n",
      "\t 50507 ' 5.433730000000001 I\n",
      "\t 50507 I 8.077539999999999 I\n",
      "\t 50508 asked 4.741709999999999 asked.\n",
      "\t 50508 asked 4.741709999999999 asked\n",
      "\t 50509 The 1.9422099999999998 The\n",
      "\t 50510 barber 13.0148 barber,\n",
      "\t 50510 barber 13.0148 barber\n",
      "\t 50502 make 4.02404 make\n",
      "\t 50503 my 5.22197 my\n",
      "\t 50504 hair 6.95754 hair\n",
      "\t 50505 like 5.17211 like\n",
      "\t **50506 Elvis 9.32302 Elvis's?'\n",
      "\t **50506 Elvis 9.32302 Elvis's\n",
      "\t 50507 's 2.92824 I\n",
      "\t 50507 ? 0.763828 I\n",
      "\t 50507 ' 4.24509 I\n",
      "\t 50507 I 6.871 I\n",
      "\t 50508 asked 5.52957 asked.\n",
      "\t 50508 asked 5.52957 asked\n",
      "\t 50509 The 1.94433 The\n",
      "\t 50510 barber 13.3712 barber,\n",
      "\t 50510 barber 13.3712 barber\n",
      "\t 50502 make 3.9064900000000002 make\n",
      "\t 50503 my 5.55872 my\n",
      "\t 50504 hair 8.88031 hair\n",
      "\t 50505 like 6.18435 like\n",
      "\t **50506 Elvis 10.0204 Elvis's?'\n",
      "\t **50506 Elvis 10.0204 Elvis's\n",
      "\t 50507 's 10.9596 I\n",
      "\t 50507 ? 0.20189100000000001 I\n",
      "\t 50507 ' 6.7869 I\n",
      "\t 50507 I 8.17447 I\n",
      "\t 50508 asked 6.9869 asked.\n",
      "\t 50508 asked 6.9869 asked\n",
      "\t 50509 The 1.88362 The\n",
      "\t 50510 UNK-LC-er 7.23442 barber,\n",
      "\t 50502 make 4.67735 make\n",
      "\t 50503 my 5.97746 my\n",
      "\t 50504 hair 5.77081 hair\n",
      "\t 50505 like 6.16023 like\n",
      "\t **50506 Elvis 10.1799 Elvis's?'\n",
      "\t **50506 Elvis 10.1799 Elvis's\n",
      "\t 50507 's 4.14723 I\n",
      "\t 50507 ? 0.265838 I\n",
      "\t 50507 ' 3.4984 I\n",
      "\t 50507 I 5.99796 I\n",
      "\t 50508 asked 4.31714 asked.\n",
      "\t 50508 asked 4.31714 asked\n",
      "\t 50509 The 1.9729299999999999 The\n",
      "\t 50510 barber 13.1325 barber,\n",
      "\t 50510 barber 13.1325 barber\n",
      "\t 50502 make 4.11319 make\n",
      "\t 50503 my 5.1724 my\n",
      "\t 50504 hair 6.59128 hair\n",
      "\t 50505 like 7.1872 like\n",
      "\t **50506 Elvis 11.9173 Elvis's?'\n",
      "\t **50506 Elvis 11.9173 Elvis's\n",
      "\t 50507 's 7.2976 I\n",
      "\t 50507 ? 0.426196 I\n",
      "\t 50507 ' 3.06612 I\n",
      "\t 50507 I 7.40345 I\n",
      "\t 50508 asked 5.74674 asked.\n",
      "\t 50508 asked 5.74674 asked\n",
      "\t 50509 The 1.86353 The\n",
      "\t 50510 UNK-LC-er 7.5643899999999995 barber,\n",
      "\t 50502 make 3.8831800000000003 make\n",
      "\t 50503 my 5.74104 my\n",
      "\t 50504 hair 6.16875 hair\n",
      "\t 50505 like 6.57673 like\n",
      "\t **50506 Elvis 9.75047 Elvis's?'\n",
      "\t **50506 Elvis 9.75047 Elvis's\n",
      "\t 50507 's 3.9085 I\n",
      "\t 50507 ? 1.8653099999999998 I\n",
      "\t 50507 ' 4.77198 I\n",
      "\t 50507 I 7.06526 I\n",
      "\t 50508 asked 5.00402 asked.\n",
      "\t 50508 asked 5.00402 asked\n",
      "\t 50509 The 1.87747 The\n",
      "\t 50510 barber 13.1736 barber,\n",
      "\t 50510 barber 13.1736 barber\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-3a6d88ea1b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_model_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-148-3a6d88ea1b9e>\u001b[0m in \u001b[0;36mmerge_model_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mharmonized_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mharmonize_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_architecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mharmonized_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-3a6d88ea1b9e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mharmonized_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mharmonize_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_architecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mharmonized_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def merge_model_results():\n",
    "    \n",
    "    final_df = []\n",
    "    \n",
    "    models = [f for f in os.listdir(\"../data/model_results\") if not f.startswith(\".\")]\n",
    "    for m in tqdm(models, desc=\"Harmonizing models\"):\n",
    "        tqdm.write(\"Harmonizing results for \" + m)\n",
    "        test_corpus = [f for f in os.listdir(\"../data/model_results/\" + m) if not f.startswith(\".\")]\n",
    "        for tc in test_corpus:\n",
    "            test_files = [f for f in os.listdir(\"../data/model_results/\" + m + \"/\" + tc) if not f.startswith(\".\")]\n",
    "            \n",
    "            for tf in tqdm(test_files, desc=\"Test files\"):\n",
    "                if tf == \"UNKS\":\n",
    "                    print(\"TODO: UNKS\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    tf = tf.split(\"_\")\n",
    "                    test_filename = tf[0]\n",
    "                    model_architecture = tf[1]\n",
    "                    training_data = tf[2]\n",
    "                    seed = tf[3].replace(\".csv\", \"\")\n",
    "                except:\n",
    "                    print(tf)\n",
    "                    \n",
    "                if tc == \"dundee\":\n",
    "                    continue\n",
    "                \n",
    "                # Special handling for the Dundee corpus\n",
    "                if tc == \"dundee\":\n",
    "                    gold_test_filename = test_filename.replace(\"wrdp\", \"\") + \"_avg\"\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + gold_test_filename + \".txt\", sep=\"\\t\", names=[\"word\", \"surprisal\"])\n",
    "                    gold_standard.insert(0, 'code', range(0,len(gold_standard)))\n",
    "                    gold_standard[\"code\"] = gold_standard[\"code\"] + int(test_filename.replace(\"tx\", \"\").replace(\"wrdp\", \"\")) * 10000\n",
    "                else:\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + test_filename + \".txt\", sep=\"\\t\")\n",
    "                                    \n",
    "                model_results = \"_\".join([test_filename, model_architecture, training_data, seed])\n",
    "                model_path = \"/\".join([\"../data/model_results\", m, tc, model_results])\n",
    "                model_results = pd.read_csv(model_path+\".csv\", sep=\"\\t\")\n",
    "                \n",
    "                # PTB-de-process model results\n",
    "                model_results.token = model_results.token.str.replace(\"-LRB-\", \"(\")\n",
    "                model_results.token = model_results.token.str.replace(\"-RRB-\", \")\")\n",
    "            \n",
    "                # TODO: EOL Handleing\n",
    "                \n",
    "                model_results = [tuple(x)[2:4] for x in model_results.values.tolist()]\n",
    "                gold_standard = [tuple(x) for x in gold_standard.values.tolist()]\n",
    "                \n",
    "                harmonized_results = harmonize_rows(gold_standard, model_results)\n",
    "                \n",
    "                result = [tuple((x[2], x[0], x[1], x[4], tc, model_architecture, training_data, seed, len(x[0]), math.log(word_freq[x[0]]+1))) for x in harmonized_results]\n",
    "                final_df.extend(result)\n",
    "                \n",
    "    df = pd.DataFrame(final_df)\n",
    "    df.columns = [\"code\", \"word\", \"surprisal\", \"psychometric\", \"corpus\", \"model\", \"training\", \"seed\", \"len\", \"freq\"]\n",
    "    df.head()\n",
    "    df.to_csv(\"../data/harmonized_results.csv\")\n",
    "    return df\n",
    "\n",
    "df = merge_model_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50506, 24),\n",
       " (60391, 24),\n",
       " (70189, 24),\n",
       " (10776, 20),\n",
       " (70248, 16),\n",
       " (70140, 14),\n",
       " (20277, 8),\n",
       " (20515, 8),\n",
       " (40199, 8),\n",
       " (40745, 8),\n",
       " (50428, 8),\n",
       " (60633, 8),\n",
       " (60735, 8),\n",
       " (60945, 8),\n",
       " (70153, 8),\n",
       " (70164, 8),\n",
       " (70247, 8),\n",
       " (70595, 8),\n",
       " (70643, 8),\n",
       " (80142, 8),\n",
       " (100302, 8),\n",
       " (100311, 8),\n",
       " (100321, 8),\n",
       " (20516, 6),\n",
       " (10878, 5),\n",
       " (10879, 5),\n",
       " (10880, 5),\n",
       " (10881, 5),\n",
       " (10882, 5)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "mismatches_old = copy(mismatches)\n",
    "mismatches_old.most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
